{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYtxCQ/hQ9eqKxYhmAdH6L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"HaPePL1ylD9z","executionInfo":{"status":"ok","timestamp":1688385093726,"user_tz":-330,"elapsed":3995,"user":{"displayName":"Vidya","userId":"07181660108449302432"}}},"outputs":[],"source":["import functools\n","import operator\n","import os\n","import time\n","import numpy as np\n","from keras.layers import Input, LSTM, Dense\n","from keras.models import Model, load_model\n","import joblib"]},{"cell_type":"code","source":["def inference_model():\n","    \"\"\"Returns the model that will be used for inference\"\"\"\n","    with open(os.path.join(config.save_model_path, 'tokenizer' + str(config.num_decoder_tokens)), 'rb') as file:\n","        tokenizer = joblib.load(file)\n","    # loading encoder model. This remains the same\n","    inf_encoder_model = load_model(os.path.join(config.save_model_path, 'encoder_model.h5'))\n","\n","    # inference decoder model loading\n","    decoder_inputs = Input(shape=(None, config.num_decoder_tokens))\n","    decoder_dense = Dense(config.num_decoder_tokens, activation='softmax')\n","    decoder_lstm = LSTM(config.latent_dim, return_sequences=True, return_state=True)\n","    decoder_state_input_h = Input(shape=(config.latent_dim,))\n","    decoder_state_input_c = Input(shape=(config.latent_dim,))\n","    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","    decoder_states = [state_h, state_c]\n","    decoder_outputs = decoder_dense(decoder_outputs)\n","    inf_decoder_model = Model(\n","        [decoder_inputs] + decoder_states_inputs,\n","        [decoder_outputs] + decoder_states)\n","    inf_decoder_model.load_weights(os.path.join(config.save_model_path, 'decoder_model_weights.h5'))\n","    return tokenizer, inf_encoder_model, inf_decoder_model"],"metadata":{"id":"m3ncJAaNl-nt"},"execution_count":null,"outputs":[]}]}